# Kafka Producer Debug: Capturing CSFLE Logs

## Problem

Setting `"Confluent.Kafka": "Debug"` in appsettings.json alone doesn't show debug logs because Confluent.Kafka uses librdkafka's native logging, not .NET's ILogger.

---

## Solution: Enable Native Confluent Debug Logging

### Step 1: Add Log Handler to Producer

âœ… **DONE** - Already added to `AvroKafkaProducerWithCSFLE.cs`:

```csharp
.SetLogHandler((producer, logMessage) =>
{
    // Maps librdkafka severity levels to .NET LogLevel
    var level = logMessage.Level switch
    {
        SyslogLevel.Debug => LogLevel.Debug,
        SyslogLevel.Info => LogLevel.Information,
        SyslogLevel.Warning => LogLevel.Warning,
        SyslogLevel.Err => LogLevel.Error,
        _ => LogLevel.Information
    };

    _logger.Log(level, 
        "ğŸ”§ Confluent.Kafka [{Facility}] {Message}", 
        logMessage.Facility, 
        logMessage.Message);
})
```

### Step 2: Enable Debug Flags in ProducerConfig

âœ… **DONE** - Already added:

```csharp
var producerConfig = new ProducerConfig
{
    // ... other settings ...
    Debug = "broker,topic,metadata,protocol,serializer",
    LogConnectionClose = true,
};
```

**Debug contexts explained:**
- `broker` - Broker connection details
- `topic` - Topic metadata
- `metadata` - Schema/metadata operations
- `protocol` - Protocol-level details (most verbose)
- `serializer` - Serialization/deserialization details

### Step 3: Update Logging Configuration

âœ… **DONE** - Already added to `appsettings.json`:

```json
{
  "Logging": {
    "LogLevel": {
      "MyDotNetApp.Services.AvroKafkaProducerWithCSFLE": "Debug",
      "MyDotNetApp.Services.AzureKeyVaultService": "Debug"
    }
  }
}
```

---

## What You'll See Now

When you call the producer endpoint after these changes:

### Confluent Logs (via SetLogHandler)
```
ğŸ”§ Confluent.Kafka [Client] Brokers added from bootstrap.servers: 1 brokers
ğŸ”§ Confluent.Kafka [TopicMetadata] Topic cached, 1 partitions, 1 replicas (broker 0)
ğŸ”§ Confluent.Kafka [Produce] TopicPartition: [topic-0] ProducerCallback triggered
ğŸ”§ Confluent.Kafka [Connection] Connected to broker at 127.0.0.1:9092 
ğŸ”§ Confluent.Kafka [Serializer] Serializing message with Avro schema
```

### Your Custom CSFLE Logs
```
ğŸ” ENCRYPTION PIPELINE START: Key=customer-123, EventType=CustomerCreated
  [1/5] Payload serialized: 256 bytes
  [2/5] Calling Azure Key Vault for encryption...
âœ… ENCRYPTED: OriginalSize=256â†’384 bytes, Algorithm=AES256-CBC, Duration=145ms
  [3/5] Creating Avro message with encrypted payload
  [4/5] Serializing to Kafka with Schema Registry...
ğŸ”§ Confluent.Kafka [Serializer] Serializing message with Avro schema
âœ… [5/5] PRODUCED to Kafka: Topic=encrypted-avro-topic, Partition=0, Offset=42
```

---

## How to Use

### 1. Rebuild the Solution
```bash
cd MyDotNetSolution
dotnet clean
dotnet build
```

### 2. Run the Application
```bash
dotnet run
```

### 3. Send Test Message
```bash
curl -X POST http://localhost:5000/api/encryptedmessages/send \
  -H "Content-Type: application/json" \
  -d '{
    "key": "test-123",
    "payload": {
      "CustomerId": "cust-456",
      "Amount": 99.99
    },
    "eventType": "test.created"
  }'
```

### 4. Watch Console Output
You should immediately see:
- âœ… Your custom pipeline logs (ğŸ”, âœ…, ğŸ”§ emojis)
- âœ… Confluent internal logs (broker, topic, serializer details)
- âœ… Azure Key Vault logs (encryption duration)

---

## Complete Log Flow

Here's what the complete flow looks like with all logs enabled:

```
â”Œâ”€ Your Code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                   â”‚
â”œâ”€ Logger: ğŸ“¤ Calling ProduceAsync                â”‚
â”‚                                                   â”‚
â”œâ”€ Logger: ğŸ” ENCRYPTION PIPELINE START           â”‚
â”‚                                                   â”‚
â”œâ”€ Logger: [1/5] Payload serialized: 256 bytes    â”‚
â”‚                                                   â”‚
â”œâ”€ Logger: [2/5] Calling Azure Key Vault          â”‚
â”‚                                                   â”‚
â”œâ”€ Confluent: ğŸ”§ Azure.Security.KeyVault...       â”‚
â”‚                                                   â”‚
â”œâ”€ Logger: âœ… ENCRYPTED: 256â†’384 bytes, 145ms    â”‚
â”‚                                                   â”‚
â”œâ”€ Logger: [3/5] Creating Avro message            â”‚
â”‚                                                   â”‚
â”œâ”€ Logger: [4/5] Serializing to Kafka             â”‚
â”‚                                                   â”‚
â”œâ”€ Confluent: ğŸ”§ Confluent.Kafka TopicMetadata... â”‚
â”‚                                                   â”‚
â”œâ”€ Confluent: ğŸ”§ Confluent.Kafka Produce...       â”‚
â”‚                                                   â”‚
â”œâ”€ Confluent: ğŸ”§ Confluent.Kafka Connection...    â”‚
â”‚                                                   â”‚
â”œâ”€ Logger: âœ… [5/5] PRODUCED to Kafka             â”‚
â”‚                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## If Still Not Seeing Logs

### Check Current Debug Level
```powershell
# Fast check
Get-Content logs/service-operations-*.txt -Tail 20 | grep -i "confluent\|encryption"
```

### Increase Verbosity Further

Edit `appsettings.json`:
```json
{
  "Logging": {
    "LogLevel": {
      "Default": "Debug",
      "MyDotNetApp": "Debug",
      "MyDotNetApp.Services": "Debug",
      "Confluent": "Debug"
    }
  }
}
```

### Enable All Kafka Debug Contexts
```csharp
Debug = "all",  // Enable ALL debug contexts
```

Or individually:
```csharp
Debug = "all",
// OR
Debug = "broker,topic,metadata,protocol,serializer,generic,security,cipher,connections,fetch",
```

---

## Debug Contexts Reference

| Context | Shows |
|---------|-------|
| `broker` | Broker discovery and connection |
| `topic` | Topic metadata and partitioning |
| `metadata` | Schema/metadata caching |
| `protocol` | WIRE protocol details (very verbose) |
| `serializer` | Avro serialization steps |
| `security` | Security/SSL/SASL details |
| `connections` | TCP connection details |
| `fetch` | Consumer fetch details |
| `generic` | Generic librdkafka details |
| `all` | Everything (very verbose) |

---

## Verify CSFLE is Actually Working

Watch for these specific log lines:

### âœ… Encryption Happened:
```
âœ… ENCRYPTED: OriginalSize=256â†’384 bytes
```
- Size should INCREASE (encryption adds overhead)

### âœ… Correct Algorithm:
```
Algorithm=AES256-CBC, KeyId=dek-kafka-csfle
```

### âœ… Correct Headers:
```
Headers=[encryption:CSFLE-AKV,key-id:dek-kafka-csfle]
```

### âœ… Message in Kafka:
```
âœ… [5/5] PRODUCED to Kafka: Topic=encrypted-avro-topic, Partition=0, Offset=42
```

---

## Common Issues & Fixes

| Issue | Cause | Fix |
|-------|-------|-----|
| No Confluent logs appear | SetLogHandler not called | Rebuild solution, restart app |
| Logs too verbose | All debug enabled | Change `Debug = "serializer"` (one context) |
| Still no encryption logs | Producer not initialized | Run `/api/encryptedmessages/diagnostics` |
| Logs don't match | Old binary still running | `dotnet clean`, then `dotnet build` |

---

## Real-World Example Output

Here's what your complete logs should look like:

```
2026-02-14 14:32:15.123 INFO: ğŸ“¤ Calling ProduceAsync: Key=test-123, EventType=test.created
2026-02-14 14:32:15.124 DEBUG: ğŸ” ENCRYPTION PIPELINE START: Key=test-123, EventType=test.created
2026-02-14 14:32:15.125 DEBUG: [1/5] Payload serialized: 256 bytes
2026-02-14 14:32:15.126 DEBUG: [2/5] Calling Azure Key Vault for encryption...
2026-02-14 14:32:15.234 DEBUG: ğŸ”§ Confluent.Kafka [Azure] Authenticating with Azure credentials
2026-02-14 14:32:15.291 INFO: âœ… ENCRYPTED: OriginalSize=256â†’384 bytes, Compression=-50%, Algorithm=AES256-CBC, KeyId=dek-kafka-csfle, Duration=165ms
2026-02-14 14:32:15.292 DEBUG: [3/5] Creating Avro message with encrypted payload
2026-02-14 14:32:15.293 DEBUG: [4/5] Serializing to Kafka with Schema Registry...
2026-02-14 14:32:15.294 DEBUG: ğŸ”§ Confluent.Kafka [BrokerMetadata] Querying for topic: encrypted-avro-topic
2026-02-14 14:32:15.310 DEBUG: ğŸ”§ Confluent.Kafka [TopicPartition] Topic resolved to partition 0, leader=1
2026-02-14 14:32:15.311 DEBUG: ğŸ”§ Confluent.Kafka [Produce] Producing to partition 0 with compression=snappy
2026-02-14 14:32:15.325 INFO: âœ… [5/5] PRODUCED to Kafka: Topic=encrypted-avro-topic, Partition=0, Offset=42, MessageSize=384, Headers=[encryption:CSFLE-AKV,key-id:dek-kafka-csfle], Duration=31ms
2026-02-14 14:32:15.326 DEBUG: ğŸ”“ ENCRYPTION PIPELINE COMPLETE (Total: 196ms)
```

---

## Summary

**What Changed:**
1. âœ… Added `SetLogHandler()` to capture Confluent logs
2. âœ… Enabled `Debug = "broker,topic,metadata,protocol,serializer"` in ProducerConfig
3. âœ… Updated appsettings.json with Debug log levels
4. âœ… Now you'll see BOTH custom pipeline logs AND Confluent internal logs

**How to Test:**
1. Rebuild: `dotnet clean && dotnet build`
2. Run: `dotnet run`
3. Call: `POST http://localhost:5000/api/encryptedmessages/send`
4. Watch console/logs for complete pipeline with ğŸ” and âœ… markers

Done! ğŸ¯
